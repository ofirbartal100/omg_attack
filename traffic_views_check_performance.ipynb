{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import flatten_dict\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from dabs.src.systems import viewmaker, viewmaker_original\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as image\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from viewmaker.src.systems.image_systems.utils import heatmap_of_view_effect\n",
    "from torchvision.utils import make_grid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show(imgs,**fig_kwr):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False,**fig_kwr)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m31367 train examples, 7842 val examples\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrafficViewMaker(\n",
       "  (model): TrafficModel(\n",
       "    (embed_modules): ModuleList()\n",
       "    (traffic_model): Net(\n",
       "      (conv1): Conv2d(3, 100, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(100, 150, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (bn2): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(150, 250, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_drop): Dropout2d(p=0.5, inplace=False)\n",
       "      (fc1): Linear(in_features=1000, out_features=350, bias=True)\n",
       "      (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
       "      (localization): Sequential(\n",
       "        (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (fc_loc): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=32, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (viewmaker): Viewmaker(\n",
       "    (act): ReLU()\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((4, 4, 4, 4))\n",
       "      (conv2d): Conv2d(4, 32, kernel_size=(9, 9), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv3): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (in3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (res1): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res2): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(130, 130, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(130, 130, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res3): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(131, 131, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(131, 131, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res4): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res5): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(133, 133, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(133, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(133, 133, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(133, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (deconv1): UpsampleConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(131, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (deconv2): UpsampleConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in5): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (deconv3): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((4, 4, 4, 4))\n",
       "      (conv2d): Conv2d(32, 3, kernel_size=(9, 9), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (memory_bank): MemoryBank()\n",
       "  (memory_bank_labels): MemoryBank()\n",
       "  (disc): TinyP2PDiscriminator(\n",
       "    (conv_block1): DescConvBlock(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (batch_norm): Identity()\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv_block2): DescConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv_block3): DescConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv_block4): DescConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (final_conv): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = OmegaConf.load('/workspace/dabs/conf/traffic.yaml')\n",
    "config.debug = True\n",
    "config.dataset = OmegaConf.load('/workspace/dabs/conf/dataset/traffic_sign_small.yaml')\n",
    "config.model = OmegaConf.load('/workspace/dabs/conf/model/traffic_model.yaml')\n",
    "\n",
    "config.dataset.batch_size = 64\n",
    "\n",
    "pl.seed_everything(config.trainer.seed)\n",
    "\n",
    "system = viewmaker_original.TrafficViewMaker(config)\n",
    "system.setup('')\n",
    "system.load_state_dict(torch.load('/workspace/dabs/exp/models/traffic_gan/presentation.ckpt')['state_dict'],strict=False)\n",
    "\n",
    "system.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"PosixPath\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/dabs/traffic_views_check_performance.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img)\u001b[39m.\u001b[39mconvert(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     image \u001b[39m=\u001b[39m transform(image)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/Image.py:2962\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2960\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 2962\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(\u001b[39m16\u001b[39;49m)\n\u001b[1;32m   2964\u001b[0m preinit()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/dabs/traffic_views_check_performance.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         labels\u001b[39m.\u001b[39mappend(\u001b[39mint\u001b[39m(\u001b[39mstr\u001b[39m(img)\u001b[39m.\u001b[39mreplace(adv_dir,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m5\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39mError in \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m img)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray(labels))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6f666972622d64616273227d7d/workspace/dabs/traffic_views_check_performance.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m X_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(data)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"PosixPath\") to str"
     ]
    }
   ],
   "source": [
    "adv_dir = \"/workspace/dabs/data/natural_images/traffic_sign/GTSRB/Validation_Adversarial_v0/Images/\"\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from pathlib import Path\n",
    "result = list(Path(adv_dir).rglob(\"*.ppm\"))\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "            [transforms.Resize((32, 32)),\n",
    "             transforms.CenterCrop((32, 32)),\n",
    "             transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for img in result:\n",
    "    try:\n",
    "        image = Image.open(img).convert(mode='RGB')\n",
    "        image = transform(image)\n",
    "        data.append(image)\n",
    "        labels.append(int(str(img).replace(adv_dir,'')[:5]))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "\n",
    "labels = torch.from_numpy(np.array(labels))\n",
    "X_test = torch.stack(data)\n",
    "\n",
    "pred=system.predict(X_test).squeeze()\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',((pred==labels).sum()/len(labels))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on augmentations of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018553495407104492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7808,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb3867edde74b7689bc0249d304eedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.seed_everything(123)\n",
    "\n",
    "no_transform = transforms.Compose(\n",
    "            [transforms.Resize((32, 32)),\n",
    "             transforms.CenterCrop((32, 32)),\n",
    "             transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "# Resize, normalize and jitter image brightness\n",
    "data_jitter_brightness = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    # transforms.ColorJitter(brightness=-5),\n",
    "    transforms.ColorJitter(brightness=5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image saturation\n",
    "data_jitter_saturation = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(saturation=5),\n",
    "    # transforms.ColorJitter(saturation=-5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image contrast\n",
    "data_jitter_contrast = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(contrast=5),\n",
    "    # transforms.ColorJitter(contrast=-5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image hues\n",
    "data_jitter_hue = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(hue=0.4),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and rotate image\n",
    "data_rotate = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and flip image horizontally and vertically\n",
    "data_hvflip = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.RandomVerticalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and flip image horizontally\n",
    "data_hflip = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and flip image vertically\n",
    "data_vflip = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomVerticalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and shear image\n",
    "data_shear = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomAffine(degrees = 15,shear=2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and translate image\n",
    "data_translate = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomAffine(degrees = 15,translate=(0.1,0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and crop image \n",
    "data_center = transforms.Compose([\n",
    "\ttransforms.Resize((36, 36)),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and convert image to grayscale\n",
    "data_grayscale = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and convert image to grayscale\n",
    "sharpness = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2,p=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_candidates = [no_transform,data_jitter_saturation,data_jitter_contrast,data_jitter_hue,data_rotate,data_hvflip,data_hflip,data_vflip,data_shear,data_translate,data_center,data_grayscale,sharpness]\n",
    "\n",
    "# for transform in transform_candidates:\n",
    "\n",
    "# data = []\n",
    "labels = []\n",
    "for img in tqdm(result):\n",
    "    try:\n",
    "        label = int(str(img).replace(adv_dir,'')[:5])\n",
    "        image = Image.open(img).convert(mode='RGB')\n",
    "        x = torch.stack([ transform(image) for transform in transform_candidates])\n",
    "        pred=system.predict(x).squeeze()\n",
    "        labels.append(torch.hstack([torch.Tensor([label]),pred]).numpy())\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "\n",
    "results_df = pd.DataFrame(data=np.array(labels),columns=['original','no_transform','data_jitter_saturation','data_jitter_contrast','data_jitter_hue','data_rotate','data_hvflip','data_hflip','data_vflip','data_shear','data_translate','data_center','data_grayscale','sharpness'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['original','no_transform','data_jitter_saturation','data_jitter_contrast','data_jitter_hue','data_rotate','data_hvflip','data_hflip','data_vflip','data_shear','data_translate','data_center','data_grayscale','sharpness']\n",
    "\n",
    "d = {}\n",
    "for col in columns[1:]:\n",
    "    d[f'original_vs_{col}'] = [(results_df['original'] == results_df[col]).mean()]\n",
    "\n",
    "for col in columns[2:]:\n",
    "    d[f'no_transform_vs_{col}'] = [(results_df['no_transform'] == results_df[col]).mean()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_vs_no_transform</th>\n",
       "      <td>0.300077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_jitter_saturation</th>\n",
       "      <td>0.318648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_jitter_contrast</th>\n",
       "      <td>0.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_jitter_hue</th>\n",
       "      <td>0.284708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_rotate</th>\n",
       "      <td>0.301486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_hvflip</th>\n",
       "      <td>0.299821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_hflip</th>\n",
       "      <td>0.269211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_vflip</th>\n",
       "      <td>0.251793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_shear</th>\n",
       "      <td>0.301358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_translate</th>\n",
       "      <td>0.309298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_center</th>\n",
       "      <td>0.288806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_grayscale</th>\n",
       "      <td>0.277536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_sharpness</th>\n",
       "      <td>0.294185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_jitter_saturation</th>\n",
       "      <td>0.853740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_jitter_contrast</th>\n",
       "      <td>0.781762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_jitter_hue</th>\n",
       "      <td>0.848105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_rotate</th>\n",
       "      <td>0.862065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_hvflip</th>\n",
       "      <td>0.694032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_hflip</th>\n",
       "      <td>0.380379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_vflip</th>\n",
       "      <td>0.357070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_shear</th>\n",
       "      <td>0.859503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_translate</th>\n",
       "      <td>0.768186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_center</th>\n",
       "      <td>0.856814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_grayscale</th>\n",
       "      <td>0.844390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_sharpness</th>\n",
       "      <td>0.903945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "original_vs_no_transform                0.300077\n",
       "original_vs_data_jitter_saturation      0.318648\n",
       "original_vs_data_jitter_contrast        0.311475\n",
       "original_vs_data_jitter_hue             0.284708\n",
       "original_vs_data_rotate                 0.301486\n",
       "original_vs_data_hvflip                 0.299821\n",
       "original_vs_data_hflip                  0.269211\n",
       "original_vs_data_vflip                  0.251793\n",
       "original_vs_data_shear                  0.301358\n",
       "original_vs_data_translate              0.309298\n",
       "original_vs_data_center                 0.288806\n",
       "original_vs_data_grayscale              0.277536\n",
       "original_vs_sharpness                   0.294185\n",
       "no_transform_vs_data_jitter_saturation  0.853740\n",
       "no_transform_vs_data_jitter_contrast    0.781762\n",
       "no_transform_vs_data_jitter_hue         0.848105\n",
       "no_transform_vs_data_rotate             0.862065\n",
       "no_transform_vs_data_hvflip             0.694032\n",
       "no_transform_vs_data_hflip              0.380379\n",
       "no_transform_vs_data_vflip              0.357070\n",
       "no_transform_vs_data_shear              0.859503\n",
       "no_transform_vs_data_translate          0.768186\n",
       "no_transform_vs_data_center             0.856814\n",
       "no_transform_vs_data_grayscale          0.844390\n",
       "no_transform_vs_sharpness               0.903945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(d).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 100, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(100, 150, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(150, 250, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=1000, out_features=350, bias=True)\n",
       "  (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=160, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from gtsrb_pytorch.model import Net\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "from gtsrb_pytorch.data import *\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# state_dict = torch.load('/workspace/gtsrb_pytorch/model/model_40.pth')\n",
    "state_dict = torch.load('/workspace/gtsrb_pytorch/model_no_aug.pth')\n",
    "model = Net()\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "\tuse_gpu = False\n",
    "\tprint(\"Using CPU\")\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# val_data_path = '/workspace/dabs/data/adv_data/traffic_sign/07_01_2023/traffic_budget_budget=0.005/val'\n",
    "# val_data_path = '/workspace/dabs/data/adv_data/traffic_sign/FGSM/no_aug/val'\n",
    "val_data_path = '/workspace/gtsrb_pytorch/data/val_images'\n",
    "# MEAN,STD = np.array([0.3337, 0.3064, 0.3171],dtype=np.float32), np.array([ 0.2672, 0.2564, 0.2629],dtype=np.float32)\n",
    "# data_transforms = transforms.Compose([\n",
    "# \ttransforms.Resize((32, 32)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(MEAN,STD)\n",
    "# ])\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(val_data_path,transform=data_transforms),batch_size=64, shuffle=False, num_workers=4, pin_memory=use_gpu)\n",
    "# import torchattacks as ta\n",
    "   \n",
    "# atk = ta.FGSM(model, eps=0.005)\n",
    "# atk.set_normalization_used(mean=MEAN, std = STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,val_loader):\n",
    "    correct = 0\n",
    "    for data, target in tqdm(val_loader):\n",
    "        # with torch.no_grad():\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if use_gpu:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        # data.require\n",
    "        output = model.forward_original(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 110.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_transforms: acc 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 99.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_jitter_brightness: acc 64.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 97.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_jitter_saturation: acc 85.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 90.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_jitter_contrast: acc 74.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 78.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_jitter_hue: acc 89.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 101.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_rotate: acc 92.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 107.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_hvflip: acc 22.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 102.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_hflip: acc 42.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 96.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_vflip: acc 24.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 91.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_shear: acc 92.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 101.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_translate: acc 68.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 104.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_center: acc 93.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 94.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_grayscale: acc 91.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traffic_transforms = {'data_transforms': data_transforms,'data_jitter_brightness': data_jitter_brightness,'data_jitter_saturation': data_jitter_saturation,'data_jitter_contrast': data_jitter_contrast,\n",
    "'data_jitter_hue': data_jitter_hue,'data_rotate': data_rotate,'data_hvflip': data_hvflip,'data_hflip': data_hflip,'data_vflip': data_vflip,'data_shear': data_shear,'data_translate': data_translate,\n",
    "'data_center': data_center,'data_grayscale': data_grayscale}\n",
    "\n",
    "results = dict()\n",
    "for k in traffic_transforms.keys():\n",
    "    t = traffic_transforms[k]\n",
    "    val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(val_data_path,transform=t),#,is_valid_file=lambda s: 'view' in s),\n",
    "    batch_size=32, shuffle=False, num_workers=4, pin_memory=use_gpu)\n",
    "    acc = validate(model,val_loader)\n",
    "    results[k] = acc\n",
    "    print(f'{k}: acc {acc*100.0:0.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>jitter_brightness</th>\n",
       "      <th>jitter_saturation</th>\n",
       "      <th>jitter_contrast</th>\n",
       "      <th>jitter_hue</th>\n",
       "      <th>rotate</th>\n",
       "      <th>hvflip</th>\n",
       "      <th>hflip</th>\n",
       "      <th>vflip</th>\n",
       "      <th>shear</th>\n",
       "      <th>translate</th>\n",
       "      <th>center</th>\n",
       "      <th>grayscale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.956072</td>\n",
       "      <td>0.643152</td>\n",
       "      <td>0.855039</td>\n",
       "      <td>0.742377</td>\n",
       "      <td>0.893798</td>\n",
       "      <td>0.928424</td>\n",
       "      <td>0.226873</td>\n",
       "      <td>0.427132</td>\n",
       "      <td>0.240052</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.687339</td>\n",
       "      <td>0.936693</td>\n",
       "      <td>0.914987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>0.043540</td>\n",
       "      <td>0.054910</td>\n",
       "      <td>0.047158</td>\n",
       "      <td>0.042894</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.035917</td>\n",
       "      <td>0.044186</td>\n",
       "      <td>0.033979</td>\n",
       "      <td>0.045607</td>\n",
       "      <td>0.047545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline  jitter_brightness  jitter_saturation  jitter_contrast  \\\n",
       "0  0.956072           0.643152           0.855039         0.742377   \n",
       "0  0.046512           0.026486           0.043540         0.054910   \n",
       "\n",
       "   jitter_hue    rotate    hvflip     hflip     vflip     shear  translate  \\\n",
       "0    0.893798  0.928424  0.226873  0.427132  0.240052  0.927390   0.687339   \n",
       "0    0.047158  0.042894  0.060207  0.034625  0.035917  0.044186   0.033979   \n",
       "\n",
       "     center  grayscale  \n",
       "0  0.936693   0.914987  \n",
       "0  0.045607   0.047545  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1368x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adv_pd_result = pd_result\n",
    "result = pd.concat([pd_result,adv_pd_result], axis=0)\n",
    "\n",
    "plt.figure(figsize=(19, 6))\n",
    "sns.barplot(pd_result)\n",
    "sns.barplot(adv_pd_result)\n",
    "# sns.barplot(result.iloc[1])\n",
    "plt.title('Model Performance Under FGSM + Augmantations')\n",
    "# plt.title('Model Performance Under Augmantations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1368x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_result = pd.DataFrame.from_dict({k.replace('data_',\"\").replace(\"transforms\",\"baseline\"): [results[k].item()] for k in results.keys()})\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(19, 6))\n",
    "sns.barplot(pd_result)\n",
    "plt.title('Model Performance Under FGSM + Augmantations')\n",
    "# plt.title('Model Performance Under Augmantations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_adv ASR = 93.82684417068958% ; mean additional transform ASR = 94.03389689202109%\n"
     ]
    }
   ],
   "source": [
    "raw_data_key = 'data_transforms'\n",
    "raw_adversarial = results[raw_data_key].item()\n",
    "w_transform = np.mean([results[k].item() for k in results.keys() if k!=raw_data_key])\n",
    "print(f'raw_adv ASR = {(1-raw_adversarial)*100.}% ; mean additional transform ASR = {(1-w_transform)*100.}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "a = cv2.imread('/workspace/dabs/data/adv_data/traffic_sign/FGSM/no_aug/val/0/00000_original.jpg')\n",
    "b = cv2.imread('/workspace/dabs/data/adv_data/traffic_sign/FGSM/no_aug/val/0/00000_view_1.jpg')\n",
    "c = cv2.imread('/workspace/dabs/data/adv_data/traffic_sign/FGSM/val/0/00000_original.jpg')\n",
    "d = cv2.imread('/workspace/dabs/data/adv_data/traffic_sign/FGSM/val/0/00000_view_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252,   0,   0],\n",
       "        [  0,   1,   3],\n",
       "        [251,   0, 254],\n",
       "        ...,\n",
       "        [249,   1,   0],\n",
       "        [246,   1,   0],\n",
       "        [245,   2,   0]],\n",
       "\n",
       "       [[252,   0,   0],\n",
       "        [254,   0,   2],\n",
       "        [252,   0, 253],\n",
       "        ...,\n",
       "        [253,   3,   2],\n",
       "        [248,   2,   0],\n",
       "        [249,   3,   0]],\n",
       "\n",
       "       [[252,   0, 255],\n",
       "        [255,   1,   2],\n",
       "        [252,   0,   0],\n",
       "        ...,\n",
       "        [252,   0,   0],\n",
       "        [249,   0, 255],\n",
       "        [249,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   2, 253],\n",
       "        [255,   0,   1],\n",
       "        [  0,   0,   1],\n",
       "        ...,\n",
       "        [255,   0,   0],\n",
       "        [248,   1,   0],\n",
       "        [245,   1, 255]],\n",
       "\n",
       "       [[  0,   3,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0, 251,   0],\n",
       "        ...,\n",
       "        [255, 255,   0],\n",
       "        [245,   0,   0],\n",
       "        [245,   1, 255]],\n",
       "\n",
       "       [[  2,   5,   0],\n",
       "        [  1,   1,   0],\n",
       "        [  1, 252,   0],\n",
       "        ...,\n",
       "        [254,   0,   0],\n",
       "        [249,   1,   0],\n",
       "        [245,   3,   1]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
