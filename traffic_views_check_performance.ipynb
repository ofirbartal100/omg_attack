{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import flatten_dict\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from dabs.src.systems import viewmaker, viewmaker_original\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as image\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from viewmaker.src.systems.image_systems.utils import heatmap_of_view_effect\n",
    "from torchvision.utils import make_grid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show(imgs,**fig_kwr):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False,**fig_kwr)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m31367 train examples, 7842 val examples\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrafficViewMaker(\n",
       "  (model): TrafficModel(\n",
       "    (embed_modules): ModuleList()\n",
       "    (traffic_model): Net(\n",
       "      (conv1): Conv2d(3, 100, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(100, 150, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (bn2): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(150, 250, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_drop): Dropout2d(p=0.5, inplace=False)\n",
       "      (fc1): Linear(in_features=1000, out_features=350, bias=True)\n",
       "      (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
       "      (localization): Sequential(\n",
       "        (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (fc_loc): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=32, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (viewmaker): Viewmaker(\n",
       "    (act): ReLU()\n",
       "    (conv1): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((4, 4, 4, 4))\n",
       "      (conv2d): Conv2d(4, 32, kernel_size=(9, 9), stride=(1, 1))\n",
       "    )\n",
       "    (in1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv2): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (in2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv3): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (in3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (res1): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res2): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(130, 130, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(130, 130, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res3): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(131, 131, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(131, 131, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res4): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (res5): ResidualBlock(\n",
       "      (conv1): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(133, 133, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in1): InstanceNorm2d(133, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (conv2): ConvLayer(\n",
       "        (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv2d): Conv2d(133, 133, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (in2): InstanceNorm2d(133, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (deconv1): UpsampleConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(131, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (deconv2): UpsampleConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv2d): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (in5): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (deconv3): ConvLayer(\n",
       "      (reflection_pad): ReflectionPad2d((4, 4, 4, 4))\n",
       "      (conv2d): Conv2d(32, 3, kernel_size=(9, 9), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (memory_bank): MemoryBank()\n",
       "  (memory_bank_labels): MemoryBank()\n",
       "  (disc): TinyP2PDiscriminator(\n",
       "    (conv_block1): DescConvBlock(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (batch_norm): Identity()\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv_block2): DescConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv_block3): DescConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv_block4): DescConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (final_conv): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = OmegaConf.load('/workspace/dabs/conf/traffic.yaml')\n",
    "config.debug = True\n",
    "config.dataset = OmegaConf.load('/workspace/dabs/conf/dataset/traffic_sign_small.yaml')\n",
    "config.model = OmegaConf.load('/workspace/dabs/conf/model/traffic_model.yaml')\n",
    "\n",
    "config.dataset.batch_size = 64\n",
    "\n",
    "pl.seed_everything(config.trainer.seed)\n",
    "\n",
    "system = viewmaker_original.TrafficViewMaker(config)\n",
    "system.setup('')\n",
    "system.load_state_dict(torch.load('/workspace/dabs/exp/models/traffic_gan/presentation.ckpt')['state_dict'],strict=False)\n",
    "\n",
    "system.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data accuracy:  tensor(30.0077)\n"
     ]
    }
   ],
   "source": [
    "adv_dir = \"/workspace/dabs/data/natural_images/traffic_sign/GTSRB/Validation_Adversarial_v0/Images/\"\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from pathlib import Path\n",
    "result = list(Path(adv_dir).rglob(\"*.ppm\"))\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "            [transforms.Resize((32, 32)),\n",
    "             transforms.CenterCrop((32, 32)),\n",
    "             transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for img in result:\n",
    "    try:\n",
    "        image = Image.open(img).convert(mode='RGB')\n",
    "        image = transform(image)\n",
    "        data.append(image)\n",
    "        labels.append(int(str(img).replace(adv_dir,'')[:5]))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "\n",
    "labels = torch.from_numpy(np.array(labels))\n",
    "X_test = torch.stack(data)\n",
    "\n",
    "pred=system.predict(X_test).squeeze()\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',((pred==labels).sum()/len(labels))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on augmentations of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018553495407104492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7808,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb3867edde74b7689bc0249d304eedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.seed_everything(123)\n",
    "\n",
    "no_transform = transforms.Compose(\n",
    "            [transforms.Resize((32, 32)),\n",
    "             transforms.CenterCrop((32, 32)),\n",
    "             transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "# Resize, normalize and jitter image brightness\n",
    "data_jitter_brightness = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    # transforms.ColorJitter(brightness=-5),\n",
    "    transforms.ColorJitter(brightness=5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image saturation\n",
    "data_jitter_saturation = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(saturation=5),\n",
    "    # transforms.ColorJitter(saturation=-5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image contrast\n",
    "data_jitter_contrast = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(contrast=5),\n",
    "    # transforms.ColorJitter(contrast=-5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image hues\n",
    "data_jitter_hue = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(hue=0.4),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and rotate image\n",
    "data_rotate = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and flip image horizontally and vertically\n",
    "data_hvflip = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.RandomVerticalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and flip image horizontally\n",
    "data_hflip = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and flip image vertically\n",
    "data_vflip = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomVerticalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and shear image\n",
    "data_shear = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomAffine(degrees = 15,shear=2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and translate image\n",
    "data_translate = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomAffine(degrees = 15,translate=(0.1,0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and crop image \n",
    "data_center = transforms.Compose([\n",
    "\ttransforms.Resize((36, 36)),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and convert image to grayscale\n",
    "data_grayscale = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Resize, normalize and convert image to grayscale\n",
    "sharpness = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2,p=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_candidates = [no_transform,data_jitter_saturation,data_jitter_contrast,data_jitter_hue,data_rotate,data_hvflip,data_hflip,data_vflip,data_shear,data_translate,data_center,data_grayscale,sharpness]\n",
    "\n",
    "# for transform in transform_candidates:\n",
    "\n",
    "# data = []\n",
    "labels = []\n",
    "for img in tqdm(result):\n",
    "    try:\n",
    "        label = int(str(img).replace(adv_dir,'')[:5])\n",
    "        image = Image.open(img).convert(mode='RGB')\n",
    "        x = torch.stack([ transform(image) for transform in transform_candidates])\n",
    "        pred=system.predict(x).squeeze()\n",
    "        labels.append(torch.hstack([torch.Tensor([label]),pred]).numpy())\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "\n",
    "results_df = pd.DataFrame(data=np.array(labels),columns=['original','no_transform','data_jitter_saturation','data_jitter_contrast','data_jitter_hue','data_rotate','data_hvflip','data_hflip','data_vflip','data_shear','data_translate','data_center','data_grayscale','sharpness'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['original','no_transform','data_jitter_saturation','data_jitter_contrast','data_jitter_hue','data_rotate','data_hvflip','data_hflip','data_vflip','data_shear','data_translate','data_center','data_grayscale','sharpness']\n",
    "\n",
    "d = {}\n",
    "for col in columns[1:]:\n",
    "    d[f'original_vs_{col}'] = [(results_df['original'] == results_df[col]).mean()]\n",
    "\n",
    "for col in columns[2:]:\n",
    "    d[f'no_transform_vs_{col}'] = [(results_df['no_transform'] == results_df[col]).mean()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_vs_no_transform</th>\n",
       "      <td>0.300077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_jitter_saturation</th>\n",
       "      <td>0.318648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_jitter_contrast</th>\n",
       "      <td>0.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_jitter_hue</th>\n",
       "      <td>0.284708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_rotate</th>\n",
       "      <td>0.301486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_hvflip</th>\n",
       "      <td>0.299821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_hflip</th>\n",
       "      <td>0.269211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_vflip</th>\n",
       "      <td>0.251793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_shear</th>\n",
       "      <td>0.301358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_translate</th>\n",
       "      <td>0.309298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_center</th>\n",
       "      <td>0.288806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_data_grayscale</th>\n",
       "      <td>0.277536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_vs_sharpness</th>\n",
       "      <td>0.294185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_jitter_saturation</th>\n",
       "      <td>0.853740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_jitter_contrast</th>\n",
       "      <td>0.781762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_jitter_hue</th>\n",
       "      <td>0.848105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_rotate</th>\n",
       "      <td>0.862065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_hvflip</th>\n",
       "      <td>0.694032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_hflip</th>\n",
       "      <td>0.380379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_vflip</th>\n",
       "      <td>0.357070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_shear</th>\n",
       "      <td>0.859503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_translate</th>\n",
       "      <td>0.768186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_center</th>\n",
       "      <td>0.856814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_data_grayscale</th>\n",
       "      <td>0.844390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_transform_vs_sharpness</th>\n",
       "      <td>0.903945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "original_vs_no_transform                0.300077\n",
       "original_vs_data_jitter_saturation      0.318648\n",
       "original_vs_data_jitter_contrast        0.311475\n",
       "original_vs_data_jitter_hue             0.284708\n",
       "original_vs_data_rotate                 0.301486\n",
       "original_vs_data_hvflip                 0.299821\n",
       "original_vs_data_hflip                  0.269211\n",
       "original_vs_data_vflip                  0.251793\n",
       "original_vs_data_shear                  0.301358\n",
       "original_vs_data_translate              0.309298\n",
       "original_vs_data_center                 0.288806\n",
       "original_vs_data_grayscale              0.277536\n",
       "original_vs_sharpness                   0.294185\n",
       "no_transform_vs_data_jitter_saturation  0.853740\n",
       "no_transform_vs_data_jitter_contrast    0.781762\n",
       "no_transform_vs_data_jitter_hue         0.848105\n",
       "no_transform_vs_data_rotate             0.862065\n",
       "no_transform_vs_data_hvflip             0.694032\n",
       "no_transform_vs_data_hflip              0.380379\n",
       "no_transform_vs_data_vflip              0.357070\n",
       "no_transform_vs_data_shear              0.859503\n",
       "no_transform_vs_data_translate          0.768186\n",
       "no_transform_vs_data_center             0.856814\n",
       "no_transform_vs_data_grayscale          0.844390\n",
       "no_transform_vs_sharpness               0.903945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(d).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Size Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dabs.src.datasets.natural_images import traffic_sign\n",
    "dataset = traffic_sign.TrafficSignSmall('/workspace/dabs/data/')\n",
    "from types import MethodType\n",
    "\n",
    "def new_m(self,x):\n",
    "    return x\n",
    "\n",
    "dataset.transforms = MethodType(new_m, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_shapes = []\n",
    "for index, image, label in dataset:\n",
    "    min_shapes.append(min(image.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(min_shapes,discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Percent'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(min_shapes,discrete=True,cumulative=True,stat='percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
